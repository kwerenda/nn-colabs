{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwerenda/nn-colabs/blob/main/makemore_part1_bigrams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "E01: train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?"
      ],
      "metadata": {
        "id": "Zi4mDrK4ms_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read the input data"
      ],
      "metadata": {
        "id": "CdQJhMjMnYA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kwerenda/nn-colabs.git\n",
        "%cd nn-colabs"
      ],
      "metadata": {
        "id": "lSAzPgZHqEgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a940b439-21f4-4f83-844c-231f70ab5372"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nn-colabs'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 18 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (18/18), 492.07 KiB | 3.54 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "/content/nn-colabs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4-EgA3ijlNAW"
      },
      "outputs": [],
      "source": [
        "words = open('data/names.txt', 'r').read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y-uHcKP_lNAX",
        "outputId": "7dd565b0-8487-4879-88cb-019dd477113c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma',\n",
              " 'olivia',\n",
              " 'ava',\n",
              " 'isabella',\n",
              " 'sophia',\n",
              " 'charlotte',\n",
              " 'mia',\n",
              " 'amelia',\n",
              " 'harper',\n",
              " 'evelyn']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "words[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YLpXn6_RlNAX",
        "outputId": "357eea12-c0a6-44fa-e607-431ec0519a7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32033"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "len(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7IF5MMHxlNAX",
        "outputId": "989e1180-5b23-4279-b9b3-ce8a236de1ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "min(len(w) for w in words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wowGYPC7lNAX",
        "outputId": "b7ef3500-700c-480c-c8be-bcdbd42ae37c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "max(len(w) for w in words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bigram model"
      ],
      "metadata": {
        "id": "QZGD4XmYo-6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bigram counting model"
      ],
      "metadata": {
        "id": "iWCVUzBupFHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create trigrams for counting"
      ],
      "metadata": {
        "id": "CfuG0cZAnc8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "IzOXgN5Ss46D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WusQFO2RlNAX"
      },
      "outputs": [],
      "source": [
        "t = defaultdict(int)\n",
        "for w in words:\n",
        "  chs = ['<S>'] + list(w) + ['<E>']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    trigram = (ch1 + ch2 , ch2)\n",
        "    t[trigram] += 1\n",
        "    # t.get(bigram, 0) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "d0iegfoslNAX"
      },
      "outputs": [],
      "source": [
        "sorted(t.items(), key = lambda kv: -kv[1])[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkwWMAOxlNAX"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYeyu_14lNAY"
      },
      "outputs": [],
      "source": [
        "N = torch.zeros((27, 27), dtype=torch.int32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encode chars to ints.\n",
        "Use `.` for word ending and beginning.\n",
        "\n"
      ],
      "metadata": {
        "id": "t4rarrj6tU5Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBfjIt3hlNAY"
      },
      "outputs": [],
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kI8tWcPZlNAY"
      },
      "outputs": [],
      "source": [
        "\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    N[ix1, ix2] += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAjrfH4VlNAY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.imshow(N, cmap='Blues')\n",
        "for i in range(27):\n",
        "    for j in range(27):\n",
        "        chstr = itos[i] + itos[j]\n",
        "        plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color='gray')\n",
        "        plt.text(j, i, N[i, j].item(), ha=\"center\", va=\"top\", color='gray')\n",
        "plt.axis('off');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzvJhTRmlNAY"
      },
      "outputs": [],
      "source": [
        "N[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxR7JzL-lNAY"
      },
      "outputs": [],
      "source": [
        "p = N[0].float()\n",
        "p = p / p.sum()\n",
        "p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2IFvQtqlNAY"
      },
      "outputs": [],
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "itos[ix]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jESQnk3MlNAY"
      },
      "outputs": [],
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "p = torch.rand(3, generator=g)\n",
        "p = p / p.sum()\n",
        "p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEj4YOX0lNAY"
      },
      "outputs": [],
      "source": [
        "torch.multinomial(p, num_samples=100, replacement=True, generator=g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knycWtSNlNAY"
      },
      "outputs": [],
      "source": [
        "p.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4noYZpUlNAY"
      },
      "outputs": [],
      "source": [
        "P.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHwcu4OKlNAY"
      },
      "outputs": [],
      "source": [
        "P.sum(1, keepdim=True).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MNLGwealNAY"
      },
      "outputs": [],
      "source": [
        "# 27, 27\n",
        "# 27,  1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA9F92OzlNAY"
      },
      "outputs": [],
      "source": [
        "P.sum(1).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCKtqOO5lNAY"
      },
      "outputs": [],
      "source": [
        "# 27, 27\n",
        "#  1, 27"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVC0Qh08lNAZ"
      },
      "outputs": [],
      "source": [
        "P = (N+1).float()\n",
        "P /= P.sum(1, keepdims=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvnSSMTMlNAZ"
      },
      "outputs": [],
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  out = []\n",
        "  ix = 0\n",
        "  while True:\n",
        "    p = P[ix]\n",
        "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix])\n",
        "    if ix == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfH1yP6glNAZ"
      },
      "outputs": [],
      "source": [
        "# GOAL: maximize likelihood of the data w.r.t. model parameters (statistical modeling)\n",
        "# equivalent to maximizing the log likelihood (because log is monotonic)\n",
        "# equivalent to minimizing the negative log likelihood\n",
        "# equivalent to minimizing the average negative log likelihood\n",
        "\n",
        "# log(a*b*c) = log(a) + log(b) + log(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMcx5BsklNAZ"
      },
      "outputs": [],
      "source": [
        "log_likelihood = 0.0\n",
        "n = 0\n",
        "\n",
        "for w in words:\n",
        "#for w in [\"andrejq\"]:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    prob = P[ix1, ix2]\n",
        "    logprob = torch.log(prob)\n",
        "    log_likelihood += logprob\n",
        "    n += 1\n",
        "    #print(f'{ch1}{ch2}: {prob:.4f} {logprob:.4f}')\n",
        "\n",
        "print(f'{log_likelihood=}')\n",
        "nll = -log_likelihood\n",
        "print(f'{nll=}')\n",
        "print(f'{nll/n}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the neural net"
      ],
      "metadata": {
        "id": "PgfkehDGpYKh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQvqvolMlNAZ"
      },
      "outputs": [],
      "source": [
        "# create the training set of trigrams (x,y)\n",
        "xs, ys = [], []\n",
        "\n",
        "for w in words[:1]:\n",
        "  chs = ['..'] + list(w) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    print(ch1, ch2)\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RgfFiCllNAZ"
      },
      "outputs": [],
      "source": [
        "xs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYpahSVglNAZ"
      },
      "outputs": [],
      "source": [
        "ys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmvfHPuUlNAZ"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "xenc = F.one_hot(xs, num_classes=27).float()\n",
        "xenc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7TNQpp8lNAZ"
      },
      "outputs": [],
      "source": [
        "xenc.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YG3FmTdRlNAZ"
      },
      "outputs": [],
      "source": [
        "plt.imshow(xenc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdRpohK5lNAZ"
      },
      "outputs": [],
      "source": [
        "xenc.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zQ3O_SdlNAZ"
      },
      "outputs": [],
      "source": [
        "W = torch.randn((27, 1))\n",
        "xenc @ W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RxpE_E4lNAZ"
      },
      "outputs": [],
      "source": [
        "logits = xenc @ W # log-counts\n",
        "counts = logits.exp() # equivalent N\n",
        "probs = counts / counts.sum(1, keepdims=True)\n",
        "probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0t8h98ulNAZ"
      },
      "outputs": [],
      "source": [
        "probs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZFDhC65lNAZ"
      },
      "outputs": [],
      "source": [
        "probs[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sawce_T_lNAZ"
      },
      "outputs": [],
      "source": [
        "probs[0].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGIWbMFjlNAa"
      },
      "outputs": [],
      "source": [
        "# (5, 27) @ (27, 27) -> (5, 27)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6Y4F5HwlNAa"
      },
      "outputs": [],
      "source": [
        "# SUMMARY ------------------------------>>>>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiMVBWJ5lNAa"
      },
      "outputs": [],
      "source": [
        "xs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ttwtKXJlNAa"
      },
      "outputs": [],
      "source": [
        "ys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXkTU5JblNAa"
      },
      "outputs": [],
      "source": [
        "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27, 27), generator=g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkjPO6THlNAa"
      },
      "outputs": [],
      "source": [
        "xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
        "logits = xenc @ W # predict log-counts\n",
        "counts = logits.exp() # counts, equivalent to N\n",
        "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "# btw: the last 2 lines here are together called a 'softmax'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8V4xEogulNAa"
      },
      "outputs": [],
      "source": [
        "probs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJ9i2_rvlNAa"
      },
      "outputs": [],
      "source": [
        "\n",
        "nlls = torch.zeros(5)\n",
        "for i in range(5):\n",
        "  # i-th bigram:\n",
        "  x = xs[i].item() # input character index\n",
        "  y = ys[i].item() # label character index\n",
        "  print('--------')\n",
        "  print(f'bigram example {i+1}: {itos[x]}{itos[y]} (indexes {x},{y})')\n",
        "  print('input to the neural net:', x)\n",
        "  print('output probabilities from the neural net:', probs[i])\n",
        "  print('label (actual next character):', y)\n",
        "  p = probs[i, y]\n",
        "  print('probability assigned by the net to the the correct character:', p.item())\n",
        "  logp = torch.log(p)\n",
        "  print('log likelihood:', logp.item())\n",
        "  nll = -logp\n",
        "  print('negative log likelihood:', nll.item())\n",
        "  nlls[i] = nll\n",
        "\n",
        "print('=========')\n",
        "print('average negative log likelihood, i.e. loss =', nlls.mean().item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAya5jwOlNAa"
      },
      "outputs": [],
      "source": [
        "# --------- !!! OPTIMIZATION !!! yay --------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UJZrs2qlNAa"
      },
      "outputs": [],
      "source": [
        "xs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-s80rI_ZlNAa"
      },
      "outputs": [],
      "source": [
        "ys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaBPUCiflNAa"
      },
      "outputs": [],
      "source": [
        "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27, 27), generator=g, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKFHBr_flNAa"
      },
      "outputs": [],
      "source": [
        "# forward pass\n",
        "xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
        "logits = xenc @ W # predict log-counts\n",
        "counts = logits.exp() # counts, equivalent to N\n",
        "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "loss = -probs[torch.arange(5), ys].log().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFI_WyBPlNAa"
      },
      "outputs": [],
      "source": [
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae4QFx7FlNAa"
      },
      "outputs": [],
      "source": [
        "# backward pass\n",
        "W.grad = None # set to zero the gradient\n",
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tTuxDHvlNAa"
      },
      "outputs": [],
      "source": [
        "W.data += -0.1 * W.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --------- !!! OPTIMIZATION !!! yay, but this time actually --------------"
      ],
      "metadata": {
        "id": "JYyp9jgLlNAa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGl0BEORlNAa"
      },
      "outputs": [],
      "source": [
        "# create the dataset\n",
        "xs, ys = [], []\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "xs = torch.tensor(xs) # All first chars\n",
        "ys = torch.tensor(ys) # All second chars\n",
        "num = xs.nelement()\n",
        "print('number of examples: ', num) # All bigrams when all input words are concat into one string\n",
        "\n",
        "# initialize the 'network'\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "# Weights\n",
        "W = torch.randn((27, 27), generator=g, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W.shape"
      ],
      "metadata": {
        "id": "p3dvySgQ1t0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gradient descent"
      ],
      "metadata": {
        "id": "MSQOU2xS1QQm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYnghGT0lNAa"
      },
      "outputs": [],
      "source": [
        "# gradient descent\n",
        "for k in range(1):\n",
        "\n",
        "  # forward pass\n",
        "  xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
        "  logits = xenc @ W # predict log-counts\n",
        "  counts = logits.exp() # counts, equivalent to N\n",
        "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
        "  print(loss.item())\n",
        "\n",
        "  # backward pass\n",
        "  W.grad = None # set to zero the gradient\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  W.data += -50 * W.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFvJdoOAlNAa"
      },
      "outputs": [],
      "source": [
        "# finally, sample from the 'neural net' model\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  out = []\n",
        "  ix = 0\n",
        "  while True:\n",
        "\n",
        "    # ----------\n",
        "    # BEFORE:\n",
        "    #p = P[ix]\n",
        "    # ----------\n",
        "    # NOW:\n",
        "    xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
        "    logits = xenc @ W # predict log-counts\n",
        "    counts = logits.exp() # counts, equivalent to N\n",
        "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "    # ----------\n",
        "\n",
        "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix])\n",
        "    if ix == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thJNonjelNAb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "history_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}